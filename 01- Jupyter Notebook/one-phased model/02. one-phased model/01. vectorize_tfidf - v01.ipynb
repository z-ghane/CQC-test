{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb16ef61",
   "metadata": {},
   "source": [
    "# Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d473d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T10:12:19.772824Z",
     "start_time": "2022-06-01T10:12:19.752831Z"
    }
   },
   "outputs": [],
   "source": [
    "# -------- dataset\n",
    "# software_name = \"camel\"\n",
    "# software_name = \"cloudstack\"\n",
    "software_name = \"geode\"\n",
    "# software_name = \"hbase\"\n",
    "\n",
    "# -------- bad smell\n",
    "# bad_smell = \"CC\" # Cyclomatic Complexity\n",
    "bad_smell = \"DE\" # Design\n",
    "# bad_smell = \"NC\" # Npath Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60798d75",
   "metadata": {},
   "source": [
    "# Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cf68573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T10:12:21.709175Z",
     "start_time": "2022-06-01T10:12:21.698158Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_folder = software_name + \"_\" + bad_smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ec7eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T10:12:22.178551Z",
     "start_time": "2022-06-01T10:12:22.167537Z"
    }
   },
   "outputs": [],
   "source": [
    "if software_name == \"camel\":\n",
    "    dataset_file_name = \"camel_DE - v.02\"\n",
    "    \n",
    "elif software_name == \"cloudstack\":\n",
    "    dataset_file_name = \"cloudstack_DE - v.01\"\n",
    "    \n",
    "elif software_name == \"geode\":\n",
    "    dataset_file_name = \"geode_DE - v.01\"\n",
    "    \n",
    "else:\n",
    "    dataset_file_name = \"hbase_DE - v.01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5ba72d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T10:12:22.632308Z",
     "start_time": "2022-06-01T10:12:22.622312Z"
    }
   },
   "outputs": [],
   "source": [
    "tempPre =    \"E:/darsy/00/02- arshad/10- paper code/\"\n",
    "tempData =   \"00- My Data/Datasets/Direct Method/\"\n",
    "tempOutput = \"01- Jupyter Notebook/Direct Method/00. Output/\"\n",
    "\n",
    "pre_path_data   = tempPre + tempData   + software_name + \"/\" + sub_folder + \"/\"\n",
    "pre_path_output = tempPre + tempOutput + software_name + \"/\" + sub_folder + \"/\" + dataset_file_name + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06904c1",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5844ea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T10:12:34.704114Z",
     "start_time": "2022-06-01T10:12:23.989274Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import json\n",
    "\n",
    "import enlighten\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.text import TextCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0015ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:54.856801Z",
     "start_time": "2022-05-16T17:33:54.843798Z"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089bf03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:54.966752Z",
     "start_time": "2022-05-16T17:33:54.866788Z"
    }
   },
   "outputs": [],
   "source": [
    "!python -V\n",
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3429268e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T10:12:34.735523Z",
     "start_time": "2022-06-01T10:12:34.707538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d03d3d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124d3bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:54.982746Z",
     "start_time": "2022-05-16T17:33:54.970750Z"
    }
   },
   "outputs": [],
   "source": [
    "mypaths = {\n",
    "    \"dataset\":        pre_path_data   + dataset_file_name + \".csv\",\n",
    "    \"tfidf\": {\n",
    "        \"output_vec\": pre_path_output + \"tfidf-vector-v01.json\",\n",
    "        \"output_brt\": pre_path_output + \"bugRepTokens-v01.json\"\n",
    "    }\n",
    "}\n",
    "\n",
    "preprocessing_params = {\n",
    "    \"columns_name\":   [\"text\",  \"bug_class_2\"],\n",
    "    \"columns_dtype\" : {0: \"str\", 1: \"int64\"},\n",
    "    \"bug_classes\": [0, 1], \n",
    "    \"num_bug_classes\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f184a2",
   "metadata": {},
   "source": [
    "# I. Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1063d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:55.013737Z",
     "start_time": "2022-05-16T17:33:54.988740Z"
    }
   },
   "outputs": [],
   "source": [
    "class Rows(object):\n",
    "    def __init__(self, columns_name, bug_classes):\n",
    "        self.columns_name = columns_name\n",
    "        self.bug_classes = bug_classes\n",
    "    \n",
    "    \n",
    "    def __call__(self, df):\n",
    "        # 1. Set cells to None that have just white spaces\n",
    "        df = df.apply(self.white_spaces_to_None_, axis=1)\n",
    "        \n",
    "        # 2. Delete rows that have NaN values in each of its columns\n",
    "        df.dropna(axis=0, how=\"any\", subset=self.columns_name, inplace=True)\n",
    "        \n",
    "        # 3. Delete rows with class value other than [0, 1]\n",
    "        indexNames = df[~df[\"bug_class_2\"].isin(self.bug_classes)].index\n",
    "        df.drop(indexNames, axis=0, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    # set columns that just have white spaces to None\n",
    "    def white_spaces_to_None_(self, row):\n",
    "        for i in self.columns_name:\n",
    "            if row[i] and len(str(row[i]).strip()) == 0:\n",
    "                row[i] = None\n",
    "        return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57edc17d",
   "metadata": {},
   "source": [
    "# II. Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171d13e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:55.186628Z",
     "start_time": "2022-05-16T17:33:55.021722Z"
    }
   },
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(\n",
    "    mypaths[\"dataset\"], \n",
    "    names=preprocessing_params[\"columns_name\"], \n",
    "    dtype=preprocessing_params[\"columns_dtype\"],\n",
    "    header=None, \n",
    "    skip_blank_lines=True\n",
    ")\n",
    "\n",
    "print(\"len df_main before compose: \", len(df_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa916ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:55.763312Z",
     "start_time": "2022-05-16T17:33:55.196622Z"
    }
   },
   "outputs": [],
   "source": [
    "composed_pre = transforms.Compose([\n",
    "    Rows(\n",
    "        preprocessing_params[\"columns_name\"], \n",
    "        preprocessing_params[\"bug_classes\"]\n",
    "    )\n",
    "])\n",
    "\n",
    "df_main = composed_pre(df_main)\n",
    "\n",
    "print(\"len df_main after compose: \", len(df_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e29a07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:55.780303Z",
     "start_time": "2022-05-16T17:33:55.767311Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = df_main[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9339f1c",
   "metadata": {},
   "source": [
    "# IV. ProgressLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6ad6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:55.810689Z",
     "start_time": "2022-05-16T17:33:55.784301Z"
    }
   },
   "outputs": [],
   "source": [
    "class ProgressLines():\n",
    "    \n",
    "    def progress_lines(self, num, total, description, unit, colour):\n",
    "        desc = self.set_strings_to_equal_len_(description)\n",
    "        manager = enlighten.get_manager()\n",
    "        progresses = []\n",
    "        for i in range(num):\n",
    "            prog = manager.counter(total=total[i], desc=desc[i], unit=unit[i], color=colour[i])\n",
    "            prog.refresh()\n",
    "            progresses.append(prog)\n",
    "        self.progresses = progresses\n",
    "    \n",
    "    \n",
    "    def set_strings_to_equal_len_(self, description):\n",
    "        max_len = 0\n",
    "        longest_string_length = len(max(description, key=len))\n",
    "        w = []\n",
    "        for i, word in enumerate(description):\n",
    "            temp = longest_string_length - len(word)\n",
    "            w.append(word + \" \" * temp)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc42f32",
   "metadata": {},
   "source": [
    "# V. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0d6c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:33:55.858665Z",
     "start_time": "2022-05-16T17:33:55.816691Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    \n",
    "    docMaxTokenNo_org = 0\n",
    "    bugRepTokens = [] # [[w1, w2, w3, ...], [w1, w2, ...], ...]\n",
    "    vector_tfidf = [] # array of dictinaries: [{\"w1\": 0.1, \"w2\": 0.3, ...}, {}, ...]\n",
    "    w2vDic = {} # dic : {\"w1\": [0.1, 0.2, ...], \"w2\": [0.1, 0.3, ...], ...}\n",
    "    paddingVector = np.zeros(300, dtype=\"float32\")\n",
    "    \n",
    "    \n",
    "    # ************************** tokenize ************************** #\n",
    "    \n",
    "    def tokenize(self, texts):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        excludedTokens = {\"http\", \"url\", \"https\"}\n",
    "        \n",
    "        for i, doc in enumerate(texts):\n",
    "            thisTokens = []\n",
    "            doc = doc.lower()\n",
    "            for token in WordPunctTokenizer().tokenize(doc):\n",
    "                if (token in string.punctuation or token in stop_words or token in excludedTokens or \n",
    "                    (not re.findall(\"\\w\", token)) or re.findall(\"\\A[0-9]\", token)):\n",
    "                    continue\n",
    "                thisTokens.append(token)\n",
    "                self.w2vDic[token] = self.paddingVector\n",
    "            self.bugRepTokens.append(thisTokens)\n",
    "            if (len(thisTokens) > self.docMaxTokenNo_org):\n",
    "                self.docMaxTokenNo_org = len(thisTokens)\n",
    "    \n",
    "    \n",
    "    # calculate tfidf of corpuses words\n",
    "    def vectorize_tfidf(self):\n",
    "        texts = TextCollection(self.bugRepTokens)\n",
    "        tempDic = {}\n",
    "        \n",
    "        # --- ProgressLines\n",
    "        pl = ProgressLines()\n",
    "        pl.progress_lines(1, [len(self.bugRepTokens)], [\"vectorize_tfidf\"], [\"bug\"], [\"blue\"])\n",
    "        \n",
    "        # --- vectorize_tfidf\n",
    "        for doc in self.bugRepTokens:\n",
    "            tempDic = {term: texts.tf_idf(term, doc) for term in doc}\n",
    "            tempDic = {term: w for term, w in sorted(tempDic.items(), key=lambda item:item[1], reverse=True)}\n",
    "            self.vector_tfidf.append(tempDic)\n",
    "            pl.progresses[0].update()\n",
    "    \n",
    "    \n",
    "    def save_to_file_tfidf(self, vector_tfidf_path):\n",
    "        with open(vector_tfidf_path, \"w\") as fout:\n",
    "            json.dump(self.vector_tfidf, fout)\n",
    "#         with open(bugRepTokens_path, \"w\") as fout:\n",
    "#             json.dump(self.bugRepTokens, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e2002",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ae046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:59:39.482668Z",
     "start_time": "2022-05-16T17:33:55.865661Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = Preprocessing()\n",
    "\n",
    "ds.tokenize(texts)\n",
    "ds.vectorize_tfidf()\n",
    "\n",
    "ds.save_to_file_tfidf(\n",
    "    mypaths[\"tfidf\"][\"output_vec\"]\n",
    "    #mypaths[\"tfidf\"][\"output_brt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88660f01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:59:39.825453Z",
     "start_time": "2022-05-16T17:59:39.792473Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"df_main length:    \", len(df_main))\n",
    "print(\"bugRepTokens:      \", len(ds.bugRepTokens))\n",
    "print(\"vector_tfidf:      \", len(ds.vector_tfidf))\n",
    "print(\"docMaxTokenNo_org: \", ds.docMaxTokenNo_org)\n",
    "print(\"w2vDic:            \", len(ds.w2vDic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95324dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-pytorch-cpu_jn",
   "language": "python",
   "name": "paper-pytorch-cpu_jn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "190px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
