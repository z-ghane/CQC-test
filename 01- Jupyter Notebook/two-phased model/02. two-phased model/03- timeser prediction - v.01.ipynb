{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d47073d",
   "metadata": {},
   "source": [
    "# Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2299f83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:54.215165Z",
     "start_time": "2022-05-11T05:01:54.180189Z"
    }
   },
   "outputs": [],
   "source": [
    "which_chunck = 3\n",
    "\n",
    "# -------- method: first\n",
    "# which_method = \"first\"\n",
    "which_method = \"second\"\n",
    "\n",
    "if which_method == \"second\":\n",
    "    top_k = 20\n",
    "\n",
    "\n",
    "# -------- method_way\n",
    "method_way = \"c\" # a, b, c\n",
    "\n",
    "if (method_way == \"a\" and which_method == \"second\"):\n",
    "    bug_localization_accuracy = [1] # main data - th\n",
    "    knn_accuracy_threshold =    [1]\n",
    "\n",
    "if method_way == \"b\":\n",
    "    bug_localization_accuracy = [1] # main data - th\n",
    "    knn_accuracy_threshold = [\n",
    "        0.5, 0.55, \n",
    "        0.6, 0.65, \n",
    "        0.7, 0.75, \n",
    "        0.8, 0.85, \n",
    "        0.9, 0.95\n",
    "    ]\n",
    "\n",
    "\n",
    "if method_way == \"c\":\n",
    "    bug_localization_accuracy = [0.8]\n",
    "    knn_accuracy_threshold = [\n",
    "        0.5, 0.55, \n",
    "        0.6, 0.65, \n",
    "        0.7, 0.75, \n",
    "        0.8, 0.85, \n",
    "        0.9, 0.95\n",
    "    ]\n",
    "\n",
    "\n",
    "# -------- dataset\n",
    "# software_name = \"camel\"\n",
    "# software_name = \"cloudstack\"\n",
    "software_name = \"geode\"\n",
    "# software_name = \"HBase\"\n",
    "\n",
    "\n",
    "# -------- google colab\n",
    "# on_google_colab = True\n",
    "on_google_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bc1cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:54.231156Z",
     "start_time": "2022-05-11T05:01:54.220163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla:  [0.8]\n",
      "th:   [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n"
     ]
    }
   ],
   "source": [
    "print(\"bla: \", bug_localization_accuracy)\n",
    "print(\"th:  \", knn_accuracy_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb891f",
   "metadata": {},
   "source": [
    "# Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55696109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:54.247147Z",
     "start_time": "2022-05-11T05:01:54.234156Z"
    }
   },
   "outputs": [],
   "source": [
    "if software_name == \"camel\":\n",
    "    dataset_file_name = \"dataset_camel - v.01\"\n",
    "    dataset_file_name_ts = \"timeserAll_camel - v.01\"\n",
    "    \n",
    "elif software_name == \"cloudstack\":\n",
    "    dataset_file_name = \"cloudstack_bugs - v.01\"\n",
    "    dataset_file_name_ts = \"cloudstack_TimeSeries - v.01\"\n",
    "    \n",
    "elif software_name == \"geode\":\n",
    "    dataset_file_name = \"geode_Bug - v.01\"\n",
    "    dataset_file_name_ts = \"geode_TS - v.01\"\n",
    "    \n",
    "else:\n",
    "    dataset_file_name = \"dataset_hbase - v.03\"\n",
    "    dataset_file_name_ts = \"timeserAll - v.03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51121790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:54.277130Z",
     "start_time": "2022-05-11T05:01:54.252146Z"
    }
   },
   "outputs": [],
   "source": [
    "if on_google_colab:\n",
    "    \n",
    "    !pip install enlighten\n",
    "    !pip install --upgrade statsmodels \n",
    "    !pip install --upgrade matplotlib\n",
    "    \n",
    "    # load data from google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "    !ls \"/content/gdrive/My Drive/\"\n",
    "    \n",
    "    tempPre = \"gdrive/MyDrive/Colab Notebooks/paper/Indirect Method/\"\n",
    "    pre_path_data = tempPre + \"data/\" + software_name + \"/\"\n",
    "    \n",
    "    # you can choose one of these and comment out the other:\n",
    "    # pre_path_output = tempPre + \"output/\"\n",
    "    pre_path_output = tempPre + \"output/\" + dataset_file_name + \"/\" + which_method + \"/\"\n",
    "\n",
    "else:\n",
    "    tempPre =    \"E:/darsy/00/02- arshad/10- paper code/\"\n",
    "    tempData =   \"00- My Data/Datasets/Indirect Method/\"\n",
    "    tempOutput = \"01- Jupyter Notebook/InDirect Method/00. Output/\"\n",
    "    pre_path_data =   tempPre + tempData   + software_name + \"/\"\n",
    "    pre_path_output = tempPre + tempOutput + software_name + \"/\" + dataset_file_name + \"/\" + which_method + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f6982",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdc7cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:56.135068Z",
     "start_time": "2022-05-11T05:01:54.282128Z"
    }
   },
   "outputs": [],
   "source": [
    "import enlighten\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a1afb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:56.151062Z",
     "start_time": "2022-05-11T05:01:56.138072Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8936fc",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd594ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:56.182045Z",
     "start_time": "2022-05-11T05:01:56.158061Z"
    }
   },
   "outputs": [],
   "source": [
    "if which_method == \"first\":\n",
    "    path_folder = pre_path_data + \"first/bla={}/\".format(bug_localization_accuracy[0])\n",
    "    \n",
    "    sub_chunck_file_org =  \"{} _ bla={} - {}.csv\".format(dataset_file_name, \n",
    "                                                         bug_localization_accuracy[0], which_chunck)\n",
    "    \n",
    "    sub_chunck_file_pred = \"{} _ bla={} - {}-pred.csv\".format(dataset_file_name, \n",
    "                                                              bug_localization_accuracy[0], which_chunck)\n",
    "    \n",
    "else:\n",
    "    path_folder = pre_path_data + \"second/k={}/bla={}/\".format(top_k, bug_localization_accuracy[0])\n",
    "    \n",
    "    sub_chunck_file_org =  \"{} _ k={}, bla={} - {}.csv\".format(dataset_file_name, top_k, \n",
    "                                                               bug_localization_accuracy[0], which_chunck)\n",
    "    \n",
    "    sub_chunck_file_pred = \"{} _ k={}, bla={} - {}-pred.csv\".format(dataset_file_name, top_k, \n",
    "                                                                    bug_localization_accuracy[0], which_chunck)\n",
    "\n",
    "\n",
    "\n",
    "mypaths = {\n",
    "    \"split_dataset\":      path_folder   + sub_chunck_file_org,\n",
    "    \"timeser\":            pre_path_data + dataset_file_name_ts + \".csv\",\n",
    "    \"split_dataset_pred\": path_folder   + \"pred/\" + sub_chunck_file_pred\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "preprocessing_params = {\n",
    "    \"dataset\": {\n",
    "        # time_stamp is the time that we change the class for a bug fixing.\n",
    "        # id stands for identifier\n",
    "        \"columns_name\":   [\"bug_report_id\", \"class_id\", \"time_stamp\", \"label\"],\n",
    "        \"columns_dtype\" : {0: \"int64\", 1: \"int64\", 2: \"int64\", 3:\"int32\"}\n",
    "    },\n",
    "    \n",
    "    \"timeser\": {\n",
    "        \"columns_name\":   [\"class_id\", \"time_stamp\", \"label\"],\n",
    "        \"columns_dtype\" : {0: \"int64\", 1: \"int64\", 2:\"int32\"}\n",
    "    }\n",
    "}\n",
    "    \n",
    "\n",
    "knn_model_params = {\n",
    "    \"train_size\": 0.8,\n",
    "    \"n_neighbors\": 5\n",
    "}\n",
    "\n",
    "progress_colours = [\"webmaroon\", \"salmon\", \"orangered\", \"deeppink3\", \"crimson\", \n",
    "                    \"black\", \"blue\", \"gray\", \"cyan4\", \"darkgreen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0931b",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b1c9c",
   "metadata": {},
   "source": [
    "## df_timeserAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8cb2c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:56.403050Z",
     "start_time": "2022-05-11T05:01:56.186044Z"
    }
   },
   "outputs": [],
   "source": [
    "df_timeserAll = pd.read_csv(\n",
    "    mypaths[\"timeser\"], \n",
    "    names=preprocessing_params[\"timeser\"][\"columns_name\"], \n",
    "    dtype=preprocessing_params[\"timeser\"][\"columns_dtype\"], \n",
    "    header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d35bb",
   "metadata": {},
   "source": [
    "## df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bcf19b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:56.834187Z",
     "start_time": "2022-05-11T05:01:56.406004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/darsy/00/02- arshad/10- paper code/00- My Data/Datasets/Indirect Method/geode/second/k=20/bla=0.8/geode_Bug - v.01 _ k=20, bla=0.8 - 3.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[      bug_report_id  class_id  time_stamp  label\n",
       " 0             34007     82645  1489106000      0\n",
       " 1             34007     91501  1489106000      0\n",
       " 2             34007    103455  1489106000      0\n",
       " 3             34007    103500  1489106000     -1\n",
       " 4             34007    104356  1489106000      0\n",
       " ...             ...       ...         ...    ...\n",
       " 7007          39606    113784  1435703450      0\n",
       " 7008          39622    114566  1434766441      0\n",
       " 7009          39622    114589  1434766441      0\n",
       " 7010          39622    114541  1435080450      0\n",
       " 7011          39623    114864  1434656000      0\n",
       " \n",
       " [7012 rows x 4 columns]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mypaths[\"split_dataset\"])\n",
    "\n",
    "df_data = pd.read_csv(\n",
    "    mypaths[\"split_dataset\"], \n",
    "    names=preprocessing_params[\"dataset\"][\"columns_name\"], \n",
    "    dtype=preprocessing_params[\"dataset\"][\"columns_dtype\"], \n",
    "    header=None\n",
    ")\n",
    "\n",
    "df_data = [df_data]\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e6db2",
   "metadata": {},
   "source": [
    "# MyTimeSer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aa39a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:56.897295Z",
     "start_time": "2022-05-11T05:01:56.839128Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyTimeSer():\n",
    "    \n",
    "    def __init__(self, df_timeserAll, df_data, knn_model_params, threshold, bug_localization_accuracy):\n",
    "        self.df_data_pred = df_data\n",
    "        self.df_timeserAll = df_timeserAll\n",
    "        self.accepted_num = {}\n",
    "        self.threshold = threshold # [0.5, 0.5, ...]\n",
    "        self.bla = bug_localization_accuracy\n",
    "        self.knn_model_params = knn_model_params\n",
    "        self.time_to_train = None\n",
    "        \n",
    "        \n",
    "        for i, bla in enumerate(self.bla):\n",
    "            self.accepted_num[bla] = {\"isctss\": 0}\n",
    "            temp_df_data_pred = self.df_data_pred[i]\n",
    "            \n",
    "            for th in threshold:\n",
    "                # add prediction columns\n",
    "                new_column_name = self.prediction_column_name(th)\n",
    "                temp_df_data_pred[new_column_name] = np.nan\n",
    "                \n",
    "                # initialize self.accepted_num\n",
    "                # self.accepted_num[bla][th]: (iscts &) accup\n",
    "                self.accepted_num[bla][th] = 0\n",
    "    \n",
    "    \n",
    "    # ************************** helper ************************** #\n",
    "    \n",
    "    def prediction_column_name(self, th):\n",
    "        return \"predictions_\" + str(th)\n",
    "    \n",
    "    \n",
    "    # ************************** progress lines ************************** #\n",
    "    \n",
    "    def progress_lines(self, colours):\n",
    "        desc = self.set_strings_to_equal_len_()\n",
    "        total = len(self.df_data_pred[0])\n",
    "        manager = enlighten.get_manager()\n",
    "        progresses = []\n",
    "        for i, bla in enumerate(self.bla):\n",
    "            prog = manager.counter(total=total, desc=desc[i], unit=\"sample\", color=colours[i])\n",
    "            prog.refresh()\n",
    "            progresses.append(prog)\n",
    "        self.progresses = progresses\n",
    "    \n",
    "    \n",
    "    def set_strings_to_equal_len_(self):\n",
    "        words = []\n",
    "        for bla in self.bla:\n",
    "            desc = \"train-test-\" + str(bla)\n",
    "            words.append(desc)\n",
    "        \n",
    "        max_len = 0\n",
    "        longest_string_length = len(max(words, key=len))\n",
    "        w = []\n",
    "        for i, word in enumerate(words):\n",
    "            temp = longest_string_length - len(word)\n",
    "            w.append(word + \" \" * temp)\n",
    "        return w\n",
    "    \n",
    "    \n",
    "    # ************************** prediction ************************** #\n",
    "    \n",
    "    def make_predictions(self):\n",
    "        for i, bla in enumerate(self.bla):\n",
    "            # --- make prediction\n",
    "            self.df_data_pred[i].apply(lambda row: self.flow_(row, i, bla), axis=1)\n",
    "\n",
    "        # --- time to train\n",
    "        totalSeconds = self.progresses[-1].elapsed\n",
    "        hours = int(totalSeconds / 3600)\n",
    "        minutes = int((totalSeconds - (hours * 3600)) / 60)\n",
    "        seconds = int((totalSeconds - (hours * 3600 + minutes * 60)))\n",
    "        self.time_to_train = f\"{hours}h:{minutes}m:{seconds}s\"\n",
    "    \n",
    "    \n",
    "    def flow_(self, row, i, bla):\n",
    "        # --- extract class time series.\n",
    "        cts = self.extract_class_time_series_(row[\"class_id\"], row[\"time_stamp\"])\n",
    "        \n",
    "        # --- if cts is stationary, then make prediction & if accuracy pass the threshold, save the prediction\n",
    "        is_cts_stationary = self.testSeries_(cts)\n",
    "        if is_cts_stationary:\n",
    "            self.accepted_num[bla][\"isctss\"] += 1\n",
    "            accuracy, yhat = self.predictValue_(cts)\n",
    "            for th in self.threshold:\n",
    "                if accuracy > th:\n",
    "                    self.accepted_num[bla][th] += 1\n",
    "                    tempColumnName = self.prediction_column_name(th)\n",
    "                    self.df_data_pred[i].loc[row.name, tempColumnName] = int(yhat)\n",
    "        \n",
    "        self.progresses[i].update()\n",
    "    \n",
    "    \n",
    "    def extract_class_time_series_(self, class_id, bug_class_commitTime):\n",
    "        df_class_time_series = self.df_timeserAll[\n",
    "            (self.df_timeserAll[\"class_id\"]  == class_id) & \n",
    "            (self.df_timeserAll[\"time_stamp\"] < bug_class_commitTime)\n",
    "        ]\n",
    "        sorted_df_cts = df_class_time_series.sort_values(by=\"time_stamp\", ascending=True)\n",
    "        cts = sorted_df_cts[\"label\"].to_numpy()\n",
    "        return cts\n",
    "    \n",
    "    \n",
    "    def testSeries_(self, cts):\n",
    "        if len(cts) <= 10:\n",
    "            return False\n",
    "        \n",
    "        result = adfuller(cts)\n",
    "        critical_values = result[4].items()\n",
    "        is_cts_stationary = True\n",
    "        \n",
    "        for alpha, critical_value in critical_values:\n",
    "            ADF_Statistic = result[0]\n",
    "            if critical_value < ADF_Statistic:\n",
    "                is_cts_stationary = False\n",
    "                break\n",
    "        return is_cts_stationary\n",
    "    \n",
    "    \n",
    "    def predictValue_(self, cts):\n",
    "        max_accuracy = -1\n",
    "        best_yhat = -1\n",
    "        for query_length in range(3, 10):\n",
    "            knnX, knnY = self.knnDS_(cts, query_length)\n",
    "            query = np.array(cts[-query_length:])\n",
    "            accuracy, yhat = self.knnPredict_(knnX, knnY, query)\n",
    "            if accuracy > max_accuracy:\n",
    "                max_accuracy = accuracy\n",
    "                best_yhat = yhat\n",
    "        return (max_accuracy, best_yhat)\n",
    "    \n",
    "    \n",
    "    def knnDS_(self, cts, ql):\n",
    "        knnX = [cts[i: i + ql] for i in range(len(cts) - ql)] # [[0, -1, 1, 1, ...], [1, 0, 0, 0, ...]]\n",
    "        knnY = [cts[i + ql]    for i in range(len(cts) - ql)] # [0, 1, ...]\n",
    "        return knnX, knnY\n",
    "    \n",
    "    \n",
    "    # x: [[0, -1, 1, 1, ...], [1, 0, 0, 0, ...]]\n",
    "    # y: [0, 1, ...]\n",
    "    def knnPredict_(self, x, y, query):\n",
    "        # --- prepare train and test data\n",
    "        size = int(len(x) * self.knn_model_params[\"train_size\"])\n",
    "        xtrain, xtest = x[0: size], x[size:]\n",
    "        ytrain, ytest = y[0: size], y[size:]\n",
    "        \n",
    "        if len(xtrain) < 6:\n",
    "            return 0, 0\n",
    "        \n",
    "        # --- train model\n",
    "        knn = KNeighborsClassifier(n_neighbors=self.knn_model_params[\"n_neighbors\"])\n",
    "        knn.fit(xtrain, ytrain)\n",
    "        \n",
    "        # --- test the model\n",
    "        accuracy = knn.score(xtest, ytest)\n",
    "        \n",
    "        # --- make prediction\n",
    "        yhat = 0\n",
    "        query = query.reshape(1, -1)\n",
    "        yhat = knn.predict(query)\n",
    "        return accuracy, yhat\n",
    "    \n",
    "    \n",
    "    def free_memory(self):\n",
    "        self.df_timeserAll = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bee374",
   "metadata": {},
   "source": [
    "## obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f57fae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:01:56.927442Z",
     "start_time": "2022-05-11T05:01:56.900495Z"
    }
   },
   "outputs": [],
   "source": [
    "mt_data = MyTimeSer(\n",
    "    df_timeserAll, \n",
    "    df_data, \n",
    "    knn_model_params, \n",
    "    knn_accuracy_threshold, \n",
    "    bug_localization_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63867b9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:04:27.373986Z",
     "start_time": "2022-05-11T05:01:56.930425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".enlighten-fg-800000 {\n",
       "  color: #800000;\n",
       "}\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>train-test-0.8 100%|<span class=\"enlighten-fg-800000\">███████████████████████████████████████</span>| 7012/7012 [02:30&lt;00:00, 46.63 sample/s]</pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if knn_accuracy_threshold[0] == 1:\n",
    "    eee = df_data[0].copy()\n",
    "    eee[\"predictions_1\"] = eee[\"label\"].copy()\n",
    "    mt_data.df_data_pred = [eee]\n",
    "    mt_data.free_memory()\n",
    "else:\n",
    "    print(\"else\")\n",
    "    mt_data.progress_lines(progress_colours)\n",
    "    mt_data.make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d18e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:04:27.437954Z",
     "start_time": "2022-05-11T05:04:27.376990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0h:2m:30s\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug_report_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>label</th>\n",
       "      <th>predictions_0.5</th>\n",
       "      <th>predictions_0.55</th>\n",
       "      <th>predictions_0.6</th>\n",
       "      <th>predictions_0.65</th>\n",
       "      <th>predictions_0.7</th>\n",
       "      <th>predictions_0.75</th>\n",
       "      <th>predictions_0.8</th>\n",
       "      <th>predictions_0.85</th>\n",
       "      <th>predictions_0.9</th>\n",
       "      <th>predictions_0.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34007</td>\n",
       "      <td>82645</td>\n",
       "      <td>1489106000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34007</td>\n",
       "      <td>91501</td>\n",
       "      <td>1489106000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34007</td>\n",
       "      <td>103455</td>\n",
       "      <td>1489106000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34007</td>\n",
       "      <td>103500</td>\n",
       "      <td>1489106000</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34007</td>\n",
       "      <td>104356</td>\n",
       "      <td>1489106000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7007</th>\n",
       "      <td>39606</td>\n",
       "      <td>113784</td>\n",
       "      <td>1435703450</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7008</th>\n",
       "      <td>39622</td>\n",
       "      <td>114566</td>\n",
       "      <td>1434766441</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>39622</td>\n",
       "      <td>114589</td>\n",
       "      <td>1434766441</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>39622</td>\n",
       "      <td>114541</td>\n",
       "      <td>1435080450</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>39623</td>\n",
       "      <td>114864</td>\n",
       "      <td>1434656000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7012 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bug_report_id  class_id  time_stamp  label  predictions_0.5  \\\n",
       "0             34007     82645  1489106000      0              0.0   \n",
       "1             34007     91501  1489106000      0              NaN   \n",
       "2             34007    103455  1489106000      0              NaN   \n",
       "3             34007    103500  1489106000     -1              NaN   \n",
       "4             34007    104356  1489106000      0              NaN   \n",
       "...             ...       ...         ...    ...              ...   \n",
       "7007          39606    113784  1435703450      0              NaN   \n",
       "7008          39622    114566  1434766441      0              NaN   \n",
       "7009          39622    114589  1434766441      0              NaN   \n",
       "7010          39622    114541  1435080450      0              NaN   \n",
       "7011          39623    114864  1434656000      0              NaN   \n",
       "\n",
       "      predictions_0.55  predictions_0.6  predictions_0.65  predictions_0.7  \\\n",
       "0                  0.0              0.0               0.0              0.0   \n",
       "1                  NaN              NaN               NaN              NaN   \n",
       "2                  NaN              NaN               NaN              NaN   \n",
       "3                  NaN              NaN               NaN              NaN   \n",
       "4                  NaN              NaN               NaN              NaN   \n",
       "...                ...              ...               ...              ...   \n",
       "7007               NaN              NaN               NaN              NaN   \n",
       "7008               NaN              NaN               NaN              NaN   \n",
       "7009               NaN              NaN               NaN              NaN   \n",
       "7010               NaN              NaN               NaN              NaN   \n",
       "7011               NaN              NaN               NaN              NaN   \n",
       "\n",
       "      predictions_0.75  predictions_0.8  predictions_0.85  predictions_0.9  \\\n",
       "0                  NaN              NaN               NaN              NaN   \n",
       "1                  NaN              NaN               NaN              NaN   \n",
       "2                  NaN              NaN               NaN              NaN   \n",
       "3                  NaN              NaN               NaN              NaN   \n",
       "4                  NaN              NaN               NaN              NaN   \n",
       "...                ...              ...               ...              ...   \n",
       "7007               NaN              NaN               NaN              NaN   \n",
       "7008               NaN              NaN               NaN              NaN   \n",
       "7009               NaN              NaN               NaN              NaN   \n",
       "7010               NaN              NaN               NaN              NaN   \n",
       "7011               NaN              NaN               NaN              NaN   \n",
       "\n",
       "      predictions_0.95  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "...                ...  \n",
       "7007               NaN  \n",
       "7008               NaN  \n",
       "7009               NaN  \n",
       "7010               NaN  \n",
       "7011               NaN  \n",
       "\n",
       "[7012 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_data.free_memory()\n",
    "\n",
    "print(mt_data.time_to_train)\n",
    "print(len(mt_data.df_data_pred))\n",
    "\n",
    "mt_data.df_data_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223ba1a",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d39824ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:04:27.626966Z",
     "start_time": "2022-05-11T05:04:27.441951Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data[0].to_csv(mypaths[\"split_dataset_pred\"], index=False, na_rep=\"NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a48b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-pytorch-cpu_jn",
   "language": "python",
   "name": "paper-pytorch-cpu_jn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
